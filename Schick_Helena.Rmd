---
title: "Startup Success Prediction"
subtitle: "Programming Languages - Project by Helena Schick"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

# Plan
## Identify Use Case
The objective of this project is to predict the success of startups. A startup is a new company founded by an entrepreneur with the intent to grow beyond the solo founder according to [wikipedia](https://en.wikipedia.org/wiki/Startup_company). 
Startups play major role in the economy, as they foster innovation and create employment as they grow. Yet, they face high uncertainty and need to find investors to continue their ideas and expand their potential. This project focuses on the investors to find companies with great potential to invest in and thus being one step ahead of the competition.
A business model canvas is used to describe the use case in more detail.

1. Customer Segments:
The costumers of this use case are investors that want to investigate the startup landscape quickly and want to make the best possible investment. 
The investors' biggest pain is the uncertainty of the investment in a startup. Even with a well-developed business plan and promising market research, there is no guarantee that the startup will be successful. Furthermore, startups are inherently risky ventures. They often have limited operating history and may face significant challenges in scaling up their operations, acquiring customers, and generating revenue. Moreover, investing in a startup requires a significant time commitment. Investors need to research potential opportunities, evaluate business plans, and actively monitor their investments. 
Their gains include high returns in the case that the startup will be successful. Especially early-stage investors have the opportunity to purchase equity at a low valuation, which can result in a significant return on investment if the company is acquired or goes public. In addition, investing in startups can help diversify an investor's portfolio. Startups can provide exposure to new market segments that may be difficult to access through traditional investments. Furthermore, some investors may be motivated by the social impact that startups can have. By investing in innovative companies that are addressing social or environmental challenges, investors can support positive change while also generating financial returns.

2. Value Proposition:
This projects addresses all of these pain points by providing detailed analysis of many variables former startups to transfer these learnings to new investments. It highlights the most important features of a startup to become successful and predicts whether a startup which is currently operating turns into a success or a failure. The success of a company is defined as the event that gives the company's founders a large sum of money through the process of M&A (Merger and Acquisition) or an IPO (Initial Public Offering). A company would be considered as failed if it had to be shut down.
This minimizes the uncertainty and risk of the investment. As this is provided in one platform, the time commitment and intense research is reduced tremendously. The data can always be extended through more startup data provided by the customers. This has the advantage that possible changes in the successful features are encountered and the use case always provides the latest and most valuable information.

3. Channels:
Specific investors will be contacted directly to learn about this startup success prediction and how to purchase it. In addition, the use case will be advertised on business platforms and online newspapers.

4. Customer Relationships:
A close customer collaboration will be created, that the investors have the information about startup success prediction and also share information about their past investments that the data is always improving and up to date.

5. Revenue Streams:
The startup success prediction can be purchased as a yearly abonnement by investors. They can get a reduction of the fee in exchange for startup investment data that can be incorporated in the analysis and prediction.

6. Key Activities:
The most important activity is always having a well optimized classification model for the startup success prediction. Another key activity is the data analysis that is used as a base for the prediction model. The third activity is to create a good user experience to visualize the key learnings and recommendations.

7. Key Resources:
The project is conducted by Helena Schick.
Jan Kirenz can be consulted for advice.

8. Key Partnerships:
The key partnerships are with the customers as well, as they provide data to improve the model.

9. Cost Structure:
There are currently no costs, as this is done volunatarily on behalf of the module "Programming Languages for Data Science".

## Frame Problem
We are investigating the characteristics of startups
Because we want to find out, if a startup will be successful
In order to decide to invest in it or not.

We want the model to classify the status of a startup
Our ideal outcome is "acquired", which means that the startup was successful
In order to reduce the uncertainty in startup investments.

## Identify Variables
For structured data problems, we need to identify potentially relevant variables.
The response variable is the categorical status (acquired or closed - if a startup is ‘acquired’ by some other organization, means the startup succeeded) and there are many explanatory variables, which include the category, location, funding rounds and amount.
The [data set](https://www.kaggle.com/datasets/manishkc06/startup-success-prediction?resource=download&select=startup+data.csv) is from kaggle and contains data about startups since the late 1990s in the United States of America.

## Define Metrics

Our success metrics are accuracy (percentage of startups that the model correctly predicts as successful or unsuccessful) and precision (indicates that the model is making fewer false positive predictions).
Our key results for the success metrics are an accuracy and precision of more than 90%.
Our project is deemed a failure, if the accuracy and precision are lower than 90%.

# Data

## Data Ingestion
### Prepare Environment

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(tidyverse)
library(conflicted)
library(dplyr)
library(visdat)
library(rsample)
library(tidymodels)
library(skimr)
library(purrr)
library(GGally)
```

### Import Data 
```{r}
path <- "/Users/helena.schick/Documents/GitHub/r-sql-startup-success/startup data.csv"

df <- read_csv(path)
```

### Data Structure

```{r}
glimpse(df)
```
```{r}
vis_dat(df)
```

### Data Corrections
```{r}
# convert all character variables to factors 
df <- 
  df %>% 
  mutate(across(where(is.character), as.factor))
```

```{r}
# remove unnecessary variables
df <- 
  dplyr::select(df, -`Unnamed: 0`, -`Unnamed: 6`, -state_code.1, -object_id)
```

### Variable List

```{r}
# define outcome variable as y_label
y_label <- 'status'

# select feature names
features <- 
  df %>%
  select(-all_of(y_label)) %>%
  names()

# create feature data for data splitting
X <- 
  df %>%
  select(all_of(features))

# list of numeric feature names
feat_num <- 
  X %>% 
  select(where(is.numeric)) %>% 
  names()

# list of categorical feature names
feat_cat <- 
  X %>% 
  select(!where(is.numeric)) %>% 
  names()

# create response for data splitting
y <- 
  df %>% 
  select(all_of(y_label))
```

## Data Splitting

### Train and Test Split

```{r}
# Fix the random numbers by setting the seed 
# This enables the analysis to be reproducible 
set.seed(42)

# Put 3/4 of the data into the training set 
data_split <- initial_split(df, 
                           prop = 3/4, 
                           strata = y_label, 
                           breaks = 4)

# Create dataframes for the two sets:
train_data <- training(data_split) 
test_data <- testing(data_split)
```

```{r}
set.seed(42)

cv_folds <- 
  vfold_cv(train_data,
           v=5,
           strata = y_label,
           breaks = 4)
```


### Data Exploration Set

```{r}
df_train <- train_data 
```

## Analyze Data
SQL and R

Connection to SQL
```{r}
library(DBI)
library(gapminder)

# Connection to database SQlite
con <- dbConnect(RSQLite::SQLite(), ":memory:")

# Write data "df_train" into database
dbWriteTable(con, "df_train", df_train)

# List tables
dbListTables(con)
```

```{sql connection=con}
SELECT *
FROM df_train
LIMIT 5;
```

Obtain all distinct observations with the status "acquired".
```{sql connection=con}
SELECT *
FROM df_train
WHERE status = 'acquired';
```
```{sql connection=con}
SELECT name, category_code, state_code, funding_total_usd, age_first_funding_year, funding_rounds, avg_participants
FROM df_train
WHERE status = "acquired"
ORDER BY funding_total_usd DESC
LIMIT 5;
```

```{sql connection=con}
SELECT category_code, state_code, funding_total_usd
FROM df_train
WHERE status = "acquired"
ORDER BY funding_total_usd DESC;
```

```{sql connection=con}
SELECT category_code, COUNT(status = "acquired") as count
FROM df_train
GROUP BY category_code
ORDER BY count DESC;
```

```{sql connection=con}
SELECT state_code, COUNT(status = "acquired") as count
FROM df_train
GROUP BY category_code
ORDER BY count DESC;
```

```{sql connection=con}
SELECT state_code, category_code, COUNT(status = "acquired") as count, AVG(funding_total_usd)
FROM df_train
WHERE age_first_funding_year < 2
GROUP BY state_code
ORDER BY AVG(funding_total_usd) DESC;
```

```{sql connection=con}
SELECT state_code, category_code, COUNT(status = "acquired") as count, AVG(funding_total_usd)
FROM df_train
WHERE age_first_funding_year < 2
GROUP BY state_code
ORDER BY count DESC;
```

```{sql connection=con}
SELECT state_code, category_code, COUNT(status = "acquired") as count , AVG(funding_total_usd)
FROM df_train
WHERE age_first_funding_year > 2
GROUP BY state_code
ORDER BY COUNT(status = "acquired") DESC;
```

```{sql connection=con}
SELECT state_code, category_code, COUNT(status = "acquired") as count , AVG(funding_total_usd)
FROM df_train
WHERE founded_at > "01/01/2007"
GROUP BY state_code
ORDER BY COUNT(status = "acquired") DESC;
```

```{sql connection=con}
SELECT state_code, category_code, COUNT(status = "acquired") as count , AVG(funding_total_usd)
FROM df_train
WHERE founded_at < "01/01/2007"
GROUP BY state_code
ORDER BY COUNT(status = "acquired") DESC;
```

### Categorical Features

```{r}
for (i in feat_cat){
  
  p <- ggplot(df_train, aes_string(x=i)) +
  geom_bar()
  
  plot(p)
  }
```

### Numerical Features

```{r}
skim(df_train)
```

```{r}
df_train %>% 
  select(all_of(feat_num)) %>% 
  ggscatmat(alpha = 0.2)
```

### Relationships

```{r}
#df_train %>%  
#  ggpairs()
```

```{r}
df_train %>% 
  select(where(is.numeric)) %>% # only select numerical data
  vis_cor(cor_method = "spearman", na_action = "pairwise.complete.obs")
```

```{r}
# calculate all correlations
#cor_res <- 
#  df_train %>%
#  select(where(is.numeric)) %>% 
#  correlate(method = "spearman", use = "pairwise.complete.obs") 

# show correlations
#cor_res %>% 
#  select(term, y_label) %>% 
#  filter(!is.na(y_label)) %>% # focus on dependent variable 
#  arrange(y_label) %>% # sort values
#  fashion() # print tidy correlations
```

## Define Schema
Usually it is a good idea to define some sort of schema that describes the expected properties of the data.
check_class()
Check Variable Class
check_cols()
Check if all Columns are Present
check_missing()
Check for Missing Values
check_new_values()
Check for New Values
check_range()
Check Range Consistency

or TFX

## Anomaly Detection

### Missing Values

### Outlier Detection

## Feature Engineering
Feature engineering is the process of using domain knowledge to extract meaningful features (attributes) from raw data. The goal of this process is to create new features which improve the predictions from our model.

### Pipelines

### Feature Transformation

#### Fix Missing Values

#### Fix Outliers

#### Feature Scaling
Standardization

#### Encoding

### Feature Extraction

### Custom Feature Operations

### Final Data Pipeline

# Model
## Select Algorithm
Supervised Learning
Classification
kNN
Naive Bayes
SVM 
Decision Tree
Logistic Regression

## Model Training & Tuning
### Feature Selection

### Training & Hyperparameter Tuning

### Evaluation
Evaluate best model on wrongest predictions

## Evaluate Model
Evaluate the final model on test data

# Deployment
RStudio's Model Management: https://solutions.posit.co/gallery/model-management/vetiver/

WebAPI with Plumber: https://www.rplumber.io/articles/introduction.html

## Validate Model

## Deploy Model

## Serve Model

## Monitor Model