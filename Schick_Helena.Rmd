---
title: "Startup Success Prediction"
subtitle: "Programming Languages - Project by Helena Schick"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

# Plan
## Identify Use Case
Using business model canvas
1. Customer Segments:
Who are the potential customers?
What are their needs and pain points?
How can we provide value to these customers?
2. Value Proposition:
What is the unique value that the startup offers to its customers?
How does the startup differentiate itself from competitors?
How can the startup communicate its value proposition to customers?
3. Channels:
What channels will the startup use to reach its target customers?
How will the startup acquire and retain customers?
What marketing and sales strategies will the startup use?
4. Customer Relationships:
How will the startup build and maintain relationships with its customers?
What customer service and support options will the startup provide?
What methods will the startup use to gather customer feedback?
5. Revenue Streams:
What are the potential revenue streams for the startup?
How will the startup price its products or services?
What monetization strategies will the startup use?
6. Key Activities:
What are the core activities required to operate the startup?
How will the startup prioritize and allocate resources?
What processes will the startup use to streamline operations?
7. Key Resources:
What resources does the startup require to operate?
How will the startup acquire and manage these resources?
What partnerships or collaborations are necessary for the startup to succeed?
8. Key Partnerships:
What external partnerships or collaborations are necessary for the startup to succeed?
How will the startup build and maintain these partnerships?
What value do these partnerships bring to the startup?
9. Cost Structure:
What are the costs associated with operating the startup?
How will the startup manage and minimize these costs?
What cost-cutting strategies will the startup use?

## Frame Problem
Provide a statement of what is to be learned and how decisions should be made.
We are investigating...
Because we want to find out...
In order to decide...

We want the model to...
Our ideal outcome is...
In order to...

## Identify Variables
For structured data problems, we need to identify potentially relevant variables.
Response variable and explanatory variables
Domain experts and literature research

## Define Metrics
Write down your metrics for success and failure with the data science project.
Our success metrics are..
Our key results for the success metrics are...
Our project is deemed a failure, if...

If we didn't use ML, we would...
If we could obtain perfect information, we would be willing to spend...

Strategy Mapping: Internal process, Customer perspective, Financial perspective in business model canvas

# Data

## Data Ingestion
### Prepare Environment

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(tidyverse)
library(conflicted)
library(dplyr)
library(visdat)
library(rsample)
library(tidymodels)
library(skimr)
library(purrr)
library(GGally)
```

### Import Data 
```{r}
path <- "/Users/helena.schick/Documents/GitHub/r-sql-startup-success/startup data.csv"

df <- read_csv(path)
```

### Data Structure

```{r}
glimpse(df)
```
```{r}
vis_dat(df)
```

### Data Corrections
```{r}
# convert all character variables to factors 
df <- 
  df %>% 
  mutate(across(where(is.character), as.factor))
```

```{r}
# remove unnecessary variables
df <- 
  dplyr::select(df, -`Unnamed: 0`, -`Unnamed: 6`, -state_code.1, -object_id)
```

### Variable List

```{r}
# define outcome variable as y_label
y_label <- 'status'

# select feature names
features <- 
  df %>%
  select(-all_of(y_label)) %>%
  names()

# create feature data for data splitting
X <- 
  df %>%
  select(all_of(features))

# list of numeric feature names
feat_num <- 
  X %>% 
  select(where(is.numeric)) %>% 
  names()

# list of categorical feature names
feat_cat <- 
  X %>% 
  select(!where(is.numeric)) %>% 
  names()

# create response for data splitting
y <- 
  df %>% 
  select(all_of(y_label))
```

## Data Splitting

### Train and Test Split

```{r}
# Fix the random numbers by setting the seed 
# This enables the analysis to be reproducible 
set.seed(42)

# Put 3/4 of the data into the training set 
data_split <- initial_split(df, 
                           prop = 3/4, 
                           strata = y_label, 
                           breaks = 4)

# Create dataframes for the two sets:
train_data <- training(data_split) 
test_data <- testing(data_split)
```

```{r}
set.seed(42)

cv_folds <- 
  vfold_cv(train_data,
           v=5,
           strata = y_label,
           breaks = 4)
```


### Data Exploration Set

```{r}
df_train <- train_data 
```

## Analyze Data
SQL and R

```{r}
skim(df_train)
```

### Categorical Features

```{r}
for (i in feat_cat){
  
  p <- ggplot(df_train, aes_string(x=i)) +
  geom_bar()
  
  plot(p)
  }
```
```{r}
df_train %>% 
  split(feat_cat) %>% 
  map(summary)
```

### Numerical Features
```{r}
df_train %>% 
  select(all_of(feat_num)) %>% 
  ggscatmat(alpha = 0.2)
```

### Relationships

```{r}
#df_train %>%  
#  ggpairs()
```

```{r}
df_train %>% 
  select(where(is.numeric)) %>% # only select numerical data
  vis_cor(cor_method = "spearman", na_action = "pairwise.complete.obs")
```

```{r}
# calculate all correlations
#cor_res <- 
#  df_train %>%
#  select(where(is.numeric)) %>% 
#  correlate(method = "spearman", use = "pairwise.complete.obs") 

# show correlations
#cor_res %>% 
#  select(term, y_label) %>% 
#  filter(!is.na(y_label)) %>% # focus on dependent variable 
#  arrange(y_label) %>% # sort values
#  fashion() # print tidy correlations
```

## Define Schema
Usually it is a good idea to define some sort of schema that describes the expected properties of the data.
check_class()
Check Variable Class
check_cols()
Check if all Columns are Present
check_missing()
Check for Missing Values
check_new_values()
Check for New Values
check_range()
Check Range Consistency

or TFX

## Anomaly Detection

### Missing Values

### Outlier Detection

## Feature Engineering
Feature engineering is the process of using domain knowledge to extract meaningful features (attributes) from raw data. The goal of this process is to create new features which improve the predictions from our model.

### Pipelines

### Feature Transformation

#### Fix Missing Values

#### Fix Outliers

#### Feature Scaling
Standardization

#### Encoding

### Feature Extraction

### Custom Feature Operations

### Final Data Pipeline

# Model
## Select Algorithm
Supervised Learning
Classification
kNN
Naive Bayes
SVM 
Decision Tree
Logistic Regression

## Model Training & Tuning
### Feature Selection

### Training & Hyperparameter Tuning

### Evaluation
Evaluate best model on wrongest predictions

## Evaluate Model
Evaluate the final model on test data

# Deployment
RStudio's Model Management: https://solutions.posit.co/gallery/model-management/vetiver/

WebAPI with Plumber: https://www.rplumber.io/articles/introduction.html

## Validate Model

## Deploy Model

## Serve Model

## Monitor Model