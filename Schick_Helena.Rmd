---
title: "Startup Success Prediction"
subtitle: "Programming Languages - Project by Helena Schick"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

# Plan
## Identify Use Case
The objective of this project is to predict the success of startups. A startup is a new company founded by an entrepreneur with the intent to grow beyond the solo founder according to [wikipedia](https://en.wikipedia.org/wiki/Startup_company). 
Startups play major role in the economy, as they foster innovation and create employment as they grow. Yet, they face high uncertainty and need to find investors to continue their ideas and expand their potential. This project focuses on the investors to find companies with great potential to invest in and thus being one step ahead of the competition.
A business model canvas is used to describe the use case in more detail.

1. Customer Segments:
The costumers of this use case are investors that want to investigate the startup landscape quickly and want to make the best possible investment. 
The investors' biggest pain is the uncertainty of the investment in a startup. Even with a well-developed business plan and promising market research, there is no guarantee that the startup will be successful. Furthermore, startups are inherently risky ventures. They often have limited operating history and may face significant challenges in scaling up their operations, acquiring customers, and generating revenue. Moreover, investing in a startup requires a significant time commitment. Investors need to research potential opportunities, evaluate business plans, and actively monitor their investments. 
Their gains include high returns in the case that the startup will be successful. Especially early-stage investors have the opportunity to purchase equity at a low valuation, which can result in a significant return on investment if the company is acquired or goes public. In addition, investing in startups can help diversify an investor's portfolio. Startups can provide exposure to new market segments that may be difficult to access through traditional investments. Furthermore, some investors may be motivated by the social impact that startups can have. By investing in innovative companies that are addressing social or environmental challenges, investors can support positive change while also generating financial returns.

2. Value Proposition:
This projects addresses all of these pain points by providing detailed analysis of many variables former startups to transfer these learnings to new investments. It highlights the most important features of a startup to become successful and predicts whether a startup which is currently operating turns into a success or a failure. The success of a company is defined as the event that gives the company's founders a large sum of money through the process of M&A (Merger and Acquisition) or an IPO (Initial Public Offering). A company would be considered as failed if it had to be shut down.
This minimizes the uncertainty and risk of the investment. As this is provided in one platform, the time commitment and intense research is reduced tremendously. The data can always be extended through more startup data provided by the customers. This has the advantage that possible changes in the successful features are encountered and the use case always provides the latest and most valuable information.

3. Channels:
Specific investors will be contacted directly to learn about this startup success prediction and how to purchase it. In addition, the use case will be advertised on business platforms and online newspapers.

4. Customer Relationships:
A close customer collaboration will be created, that the investors have the information about startup success prediction and also share information about their past investments that the data is always improving and up to date.

5. Revenue Streams:
The startup success prediction can be purchased as a yearly abonnement by investors. They can get a reduction of the fee in exchange for startup investment data that can be incorporated in the analysis and prediction.

6. Key Activities:
The most important activity is always having a well optimized classification model for the startup success prediction. Another key activity is the data analysis that is used as a base for the prediction model. The third activity is to create a good user experience to visualize the key learnings and recommendations.

7. Key Resources:
The project is conducted by Helena Schick.
Jan Kirenz can be consulted for advice.

8. Key Partnerships:
The key partnerships are with the customers as well, as they provide data to improve the model.

9. Cost Structure:
There are currently no costs, as this is done volunatarily on behalf of the module "Programming Languages for Data Science".

## Frame Problem
We are investigating the characteristics of startups
Because we want to find out, if a startup will be successful
In order to decide to invest in it or not.

We want the model to classify the status of a startup
Our ideal outcome is "acquired", which means that the startup was successful
In order to reduce the uncertainty in startup investments.

## Identify Variables
For structured data problems, we need to identify potentially relevant variables.
The response variable is the categorical status (acquired or closed - if a startup is ‘acquired’ by some other organization, means the startup succeeded) and there are many explanatory variables, which include the category, location, funding rounds and amount.
The [data set](https://www.kaggle.com/datasets/manishkc06/startup-success-prediction?resource=download&select=startup+data.csv) is from kaggle and contains data about startups since the late 1990s in the United States of America.

## Define Metrics

Our success metrics are accuracy (percentage of startups that the model correctly predicts as successful or unsuccessful) and precision (indicates that the model is making fewer false positive predictions).
Our key results for the success metrics are an accuracy and precision of more than 90%.
Our project is deemed a failure, if the accuracy and precision are lower than 90%.

# Data

## Data Ingestion
### Prepare Environment

At first, R is set up.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Then the necessary libraries for the entire notebook are activated and have been installed before.
```{r libraries}
library(tidyverse)
library(conflicted)
library(dplyr)
library(visdat)
library(rsample)
library(tidymodels)
library(skimr)
library(purrr)
library(GGally)
```

### Import Data 
Currently csv upload, could chnage this to upload from a database.

```{r}
path <- "/Users/helena.schick/Documents/GitHub/r-sql-startup-success/startup data.csv"

df <- read_csv(path)
```

### Data Structure

Now, we're having a first look at the data, including the column names, data types and their content.
```{r}
glimpse(df)
```
The column `Unnamed: 0` seems to be some kind of id, but has no further value and will be deleted. Labels and avg_participants cannot be understood without further context. `Unnamed: 6` is a combination of the zip code and city and thus redundant and will be deleted. The redundancy also accounts for state_code.1 and object_id.
For categories and states there are each a categorical variable and several one hot encoded ones. All are kept at this point, because the categorical is better for visualizations and data understanding, but the one hot encoded ones are needed for the classification model.
The variables are described in more detail:
| Variable | Description | Data Type |
| ------ | --: | ----------|
| state_code |  Abbreviation of US state of startup's location | character |
| latitude | Geographic North-South location of startup's location | double |
| longitude | Geographic East-West location of startup's location | double |
| zip_code | Zip code of the city of startup's location | double |
| id | Unique identification of startup | string |
| city | Name of city of startup's location | string |
| name | Name of startup | string |
| founded_at | Founding date of startup (MM/DD/YYYY) | date |
| closed_at | Closing date of startup (MM/DD/YYYY) | date |
| first_funding_at | Date of first funding received of startup (MM/DD/YYYY) | date |
| last_funding_at | Date of last funding received of startup (MM/DD/YYYY) | date |
| age_first_milestone_year | Age of startup when achieving first milestone | double |
| age_last_milestone_year | Age of startup when achieving last milestone | double |
| relationships | Amount of relationships of startup with investors, mentors,... | double |
| funding_rounds | Amount of funding rounds | double |
| funding_total_usd | Total amount of funding received in USD | double |
| milestones | Amount of milestones achieved | double |
| is_CA | Startup's location is in CA (1 = true, 0 = false) | double |
| is_NY | Startup's location is in NY (1 = true, 0 = false) | double |
| is_MA | Startup's location is in MA (1 = true, 0 = false) | double |
| is_TX | Startup's location is in TX (1 = true, 0 = false) | double |
| is_otherstate | Startup's location is in another state than CA, NY, MA or TX (1 = true, 0 = false) | double |
| category_code | Business category of startup | string |
| is_software | Startup's category is software (1 = true, 0 = false) | double |
| is_web | Startup's category is web (1 = true, 0 = false) | double |
| is_mobile | Startup's category is mobile (1 = true, 0 = false) | double |
| is_enterprise | Startup's category is enterprise (1 = true, 0 = false) | double |
| is_advertising | Startup's category is advertising (1 = true, 0 = false) | double |
| is_gamesvideo | Startup's category is gamesvideo (1 = true, 0 = false) | double |
| is_biotech | Startup's category is biotech (1 = true, 0 = false) | double |
| is_ecommerce | Startup's category is ecommerce (1 = true, 0 = false) | double |
| is_consulting | Startup's category is consulting (1 = true, 0 = false) | double |
| is_othercategory | Startup's category is another category than the previously mentioned (1 = true, 0 = false) | double |
| has_VC | Startup is financed through Venture Capital (1 = true, 0 = false) | double |
| has_angel | Startup is financed through an angel investor (1 = true, 0 = false) | double |
| has_roundA | Startup has succeeded in first major funding round (1 = true, 0 = false) | double |
| has_roundB | Startup has succeeded in second major funding round (1 = true, 0 = false) | double |
| has_roundC | Startup has succeeded in third major funding round (1 = true, 0 = false) | double |
| has_roundD | Startup has succeeded in fourth major funding round (1 = true, 0 = false) | double |
| is_top500 | Startup is listed in the Top500 startups (1 = true, 0 = false) | double |
| status | Success variable of startup (acquired = successful, closed = unsuccessful) | string |

To understand the ratio of numerical to categorical variables and view the amount of null values in the dataframe, we visualize it.
```{r}
vis_dat(df)
```
The majority of variables are numeric. There are many null values in the columns Unnamed:6, which will be deleted anyways, as well as closed_at, because this only applies, if the startup has failed, and age_first_milestone and age_last_milestone. We are keeping these two variables to get some insights about those startups that have them available.

### Data Corrections

At first, all variables of the data type character are turned into factors. This has the advantages of memory efficiency, ordering, handling of missing values, visualization and improved functionality.
```{r}
# convert all character variables to factors 
df <- 
  df %>% 
  mutate(across(where(is.character), as.factor))
```

Secondly, the variables taht represent dates are turned into the data type date.
```{r}
# convert all date variables to actual dates 
df$founded_at <- 
  as.Date(df$founded_at, format = "%m/%d/%Y")
df$closed_at <- 
  as.Date(df$closed_at, format = "%m/%d/%Y")
df$first_funding_at <- 
  as.Date(df$first_funding_at, format = "%m/%d/%Y")
df$last_funding_at <- 
  as.Date(df$last_funding_at, format = "%m/%d/%Y")
```

In the end, unnecessary varibales are removed.
```{r}
# remove unnecessary variables
df <- 
  dplyr::select(df, -`Unnamed: 0`, -`Unnamed: 6`, -state_code.1, -object_id, -labels, -avg_participants)
```

### Variable List

For easier usage in data splitting, several variable lists are created.
```{r}
# define outcome variable as y_label
y_label <- 'status'

# select feature names
features <- 
  df %>%
  select(-all_of(y_label)) %>%
  names()

# create feature data for data splitting
X <- 
  df %>%
  select(all_of(features))

# list of numeric feature names
feat_num <- 
  X %>% 
  select(where(is.numeric)) %>% 
  names()

# list of categorical feature names
feat_cat <- 
  X %>% 
  select(!where(is.numeric)) %>% 
  names()

# create response for data splitting
y <- 
  df %>% 
  select(all_of(y_label))
```

## Data Splitting

### Train and Test Split

```{r}
# Fix the random numbers by setting the seed 
# This enables the analysis to be reproducible 
set.seed(42)

# Put 3/4 of the data into the training set 
data_split <- initial_split(df, 
                           prop = 3/4, 
                           strata = y_label, 
                           breaks = 4)

# Create dataframes for the two sets:
train_data <- training(data_split) 
test_data <- testing(data_split)
```

```{r}
set.seed(42)

cv_folds <- 
  vfold_cv(train_data,
           v=5,
           strata = y_label,
           breaks = 4)
```


### Data Exploration Set

```{r}
df_train <- train_data 
```

## Analyze Data
SQL and R

Connection to SQL
```{r}
library(DBI)
library(gapminder)

# Connection to database SQlite
con <- dbConnect(RSQLite::SQLite(), ":memory:")

# Write data "df_train" into database
dbWriteTable(con, "df_train", df_train)

# List tables
dbListTables(con)
```

```{sql connection=con}
SELECT *
FROM df_train
LIMIT 5;
```

Obtain all distinct observations with the status "acquired".
```{sql connection=con}
SELECT *
FROM df_train
WHERE status = 'acquired';
```
```{sql connection=con}
SELECT name, category_code, state_code, funding_total_usd, age_first_funding_year, funding_rounds
FROM df_train
WHERE status = "acquired"
ORDER BY funding_total_usd DESC
LIMIT 5;
```

```{sql connection=con}
SELECT category_code, state_code, funding_total_usd
FROM df_train
WHERE status = "acquired"
ORDER BY funding_total_usd DESC;
```

```{sql connection=con}
SELECT category_code, COUNT(status = "acquired") as count
FROM df_train
GROUP BY category_code
ORDER BY count DESC;
```

```{sql connection=con}
SELECT state_code, COUNT(status = "acquired") as count
FROM df_train
GROUP BY category_code
ORDER BY count DESC;
```

```{sql connection=con}
SELECT state_code, category_code, COUNT(status = "acquired") as count, AVG(funding_total_usd)
FROM df_train
WHERE age_first_funding_year < 2
GROUP BY state_code
ORDER BY AVG(funding_total_usd) DESC;
```

```{sql connection=con}
SELECT state_code, category_code, COUNT(status = "acquired") as count, AVG(funding_total_usd)
FROM df_train
WHERE age_first_funding_year < 2
GROUP BY state_code
ORDER BY count DESC;
```

```{sql connection=con}
SELECT state_code, category_code, COUNT(status = "acquired") as count , AVG(funding_total_usd)
FROM df_train
WHERE age_first_funding_year > 2
GROUP BY state_code
ORDER BY COUNT(status = "acquired") DESC;
```

```{sql connection=con}
SELECT state_code, category_code, COUNT(status = "acquired") as count , AVG(funding_total_usd)
FROM df_train
WHERE founded_at > "01/01/2007"
GROUP BY state_code
ORDER BY COUNT(status = "acquired") DESC;
```

```{sql connection=con}
SELECT state_code, category_code, COUNT(status = "acquired") as count , AVG(funding_total_usd)
FROM df_train
WHERE founded_at < "01/01/2007"
GROUP BY state_code
ORDER BY COUNT(status = "acquired") DESC;
```

### Categorical Features

```{r}
for (i in feat_cat){
  
  p <- ggplot(df_train, aes_string(x=i)) +
  geom_bar()
  
  plot(p)
  }
```

### Numerical Features

```{r}
skim(df_train)
```

```{r}
df_train %>% 
  select(all_of(feat_num)) %>% 
  ggscatmat(alpha = 0.2)
```

### Relationships

```{r}
#df_train %>%  
#  ggpairs()
```

```{r}
df_train %>% 
  select(where(is.numeric)) %>% # only select numerical data
  vis_cor(cor_method = "spearman", na_action = "pairwise.complete.obs")
```

```{r}
# calculate all correlations
#cor_res <- 
#  df_train %>%
#  select(where(is.numeric)) %>% 
#  correlate(method = "spearman", use = "pairwise.complete.obs") 

# show correlations
#cor_res %>% 
#  select(term, y_label) %>% 
#  filter(!is.na(y_label)) %>% # focus on dependent variable 
#  arrange(y_label) %>% # sort values
#  fashion() # print tidy correlations
```

## Define Schema
Usually it is a good idea to define some sort of schema that describes the expected properties of the data.
check_class()
Check Variable Class
check_cols()
Check if all Columns are Present
check_missing()
Check for Missing Values
check_new_values()
Check for New Values
check_range()
Check Range Consistency

or TFX

## Anomaly Detection

### Missing Values

### Outlier Detection

## Feature Engineering
Feature engineering is the process of using domain knowledge to extract meaningful features (attributes) from raw data. The goal of this process is to create new features which improve the predictions from our model.

### Pipelines

### Feature Transformation

#### Fix Missing Values

#### Fix Outliers

#### Feature Scaling
Standardization

#### Encoding

### Feature Extraction

### Custom Feature Operations

### Final Data Pipeline

# Model
## Select Algorithm
Supervised Learning
Classification
kNN
Naive Bayes
SVM 
Decision Tree
Logistic Regression

## Model Training & Tuning
### Feature Selection

### Training & Hyperparameter Tuning

### Evaluation
Evaluate best model on wrongest predictions

## Evaluate Model
Evaluate the final model on test data

# Deployment
RStudio's Model Management: https://solutions.posit.co/gallery/model-management/vetiver/

WebAPI with Plumber: https://www.rplumber.io/articles/introduction.html

## Validate Model

## Deploy Model

## Serve Model

## Monitor Model